{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import datetime\n",
    "from dateutil.parser import *\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from transformers import dayName, dummy_days, DFStandardScaler, ZeroFillTransformer, DFFeatureUnion\n",
    "\n",
    "import pickle\n",
    "\n",
    "def ohe(self):\n",
    "    self['day_of_week'] = self.index.get_level_values('date').day_name()\n",
    "    encoded_columns = pd.get_dummies(self['day_of_week'])\n",
    "    self = self.join(encoded_columns)\n",
    "    self = self.drop('day_of_week',axis=1)\n",
    "    return self\n",
    "\n",
    "def scaling_columns_seperately(self_train,self_test,col):\n",
    "    aux_df = self_train[col]\n",
    "    std_scaler.fit(aux_df.values.reshape(-1,1))\n",
    "    aux_df = std_scaler.transform(self_train[col].values.reshape(-1,1))\n",
    "    self_train[col] = aux_df\n",
    "    \n",
    "    aux_df = self_test[col]\n",
    "    aux_df = std_scaler.transform(self_test[col].values.reshape(-1,1))\n",
    "    self_test[col] = aux_df\n",
    "\n",
    "def removing_outliers(self):\n",
    "    upper_lim1 = self['amount'].quantile(.95)\n",
    "    lower_lim1 = self['amount'].quantile(.05)\n",
    "    self=self[(self['amount'] < upper_lim1) & (self['amount'] > lower_lim1)]\n",
    "    \n",
    "    upper_lim2 = self['amount'].quantile(.975)\n",
    "    lower_lim2 = self['amount'].quantile(.025)\n",
    "    self=self[(self['amount'] < upper_lim2) & (self['amount'] > lower_lim2)]\n",
    "    \n",
    "    upper_lim3 = self['amount'].quantile(.99)\n",
    "    lower_lim3 = self['amount'].quantile(.01)\n",
    "    self=self[(self['amount'] < upper_lim3) & (self['amount'] > lower_lim3)]    \n",
    "    \n",
    "    return self\n",
    "\n",
    "def X_train_test_separation(self):\n",
    "    aux = self.loc[self.index.get_level_values('date') <= '2018-01-01']\n",
    "    train = aux.drop('amount',axis=1)\n",
    "    \n",
    "    aux = self.loc[self.index.get_level_values('date') > '2018-01-01']\n",
    "    test = aux.drop('amount',axis=1)\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "def y_train_test_separation(self):\n",
    "    aux = self.loc[self.index.get_level_values('date') <= '2018-01-01']\n",
    "    train = aux['amount']\n",
    "    \n",
    "    aux = self.loc[self.index.get_level_values('date') > '2018-01-01']\n",
    "    test = aux['amount']\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def separation (self):\n",
    "    \n",
    "    aux = self.loc[self.index.get_level_values('date') <= '2018-01-01']\n",
    "    train_X = aux.drop('amount',axis=1)\n",
    "    train_y = aux['amount']\n",
    "    \n",
    "    aux = self.loc[self.index.get_level_values('date') > '2018-01-01']\n",
    "    test_X = aux.drop('amount',axis=1)\n",
    "    test_y = aux['amount']\n",
    "    \n",
    "    return train_X, test_X, train_y, test_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "list_of_items = [38,39,40,41,57] \n",
    "\n",
    "rmse_train = []\n",
    "rmse_test = []\n",
    "\n",
    "categorical_features = ['day_of_week']\n",
    "numerical_features = ['regular_price', 'discounted_price','number_of_stores']\n",
    "\n",
    "pipeline_pickle_path = 'pipeline_pickle.pkl'\n",
    "pipeline_unpickle = open(pipeline_pickle_path, 'rb')\n",
    "  \n",
    "pipeline_from_pickle = pickle.load(pipeline_unpickle)\n",
    "\n",
    "X = pd.read_parquet(\"C:/Users/vvrhovec/Veronika/kodovi/radni_folder/parquet/X_prices_stores_amount.parquet\")\n",
    "\n",
    "X_38 = X.loc[38]\n",
    "X_39 = X.loc[39]\n",
    "X_40 = X.loc[40]\n",
    "X_41 = X.loc[41]\n",
    "X_57 = X.loc[57]\n",
    "\n",
    "X_38 = removing_outliers(X_38)\n",
    "\n",
    "X_38_train, X_38_test =  X_train_test_separation(X_38)\n",
    "y_38_train, y_38_test =  y_train_test_separation(X_38)\n",
    "\n",
    "X_38_train = pipeline_from_pickle.fit_transform(X_38_train)\n",
    "X_38_test = pipeline_from_pickle.transform(X_38_test)\n",
    "\n",
    "model_38 = lm.fit(X_38_train, y_38_train)\n",
    "\n",
    "y_38_train_predicted = model_38.predict(X_38_train)\n",
    "\n",
    "model_38.score(X_38_train,y_38_train)\n",
    "\n",
    "rmse_38_train = np.sqrt(mean_squared_error(y_38_train, y_38_train_predicted))\n",
    "rmse_train.append(rmse_38_train)\n",
    "rmse_38_train\n",
    "\n",
    "y_38_test_predicted = model_38.predict(X_38_test)\n",
    "\n",
    "rmse_38_test = np.sqrt(mean_squared_error(y_38_test, y_38_test_predicted))\n",
    "rmse_test.append(rmse_38_test)\n",
    "rmse_38_test\n",
    "\n",
    "X_39 = removing_outliers(X_39)\n",
    "\n",
    "X_39_train, X_39_test =  X_train_test_separation(X_39)\n",
    "y_39_train, y_39_test =  y_train_test_separation(X_39)\n",
    "\n",
    "X_39_train = pipeline_from_pickle.fit_transform(X_39_train)\n",
    "X_39_test = pipeline_from_pickle.transform(X_39_test)\n",
    "\n",
    "model_39 = lm.fit(X_39_train, y_39_train)\n",
    "\n",
    "y_39_train_predicted = model_39.predict(X_39_train)\n",
    "\n",
    "model_39.score(X_39_train, y_39_train)\n",
    "\n",
    "rmse_39_train = np.sqrt(mean_squared_error(y_39_train, y_39_train_predicted))\n",
    "rmse_train.append(rmse_39_train)\n",
    "rmse_39_train\n",
    "\n",
    "y_39_test_predicted = model_39.predict(X_39_test)\n",
    "\n",
    "rmse_39_test = np.sqrt(mean_squared_error(y_39_test, y_39_test_predicted))\n",
    "rmse_test.append(rmse_39_test)\n",
    "rmse_39_test\n",
    "\n",
    "X_40 = removing_outliers(X_40)\n",
    "\n",
    "X_40_train, X_40_test =  X_train_test_separation(X_40)\n",
    "y_40_train, y_40_test =  y_train_test_separation(X_40)\n",
    "\n",
    "X_40_train = pipeline_from_pickle.fit_transform(X_40_train)\n",
    "X_40_test = pipeline_from_pickle.transform(X_40_test)\n",
    "\n",
    "model_40 = lm.fit(X_40_train, y_40_train)\n",
    "\n",
    "y_40_train_predicted = model_40.predict(X_40_train)\n",
    "\n",
    "model_40.score(X_40_train, y_40_train)\n",
    "\n",
    "rmse_40_train = np.sqrt(mean_squared_error(y_40_train, y_40_train_predicted))\n",
    "rmse_train.append(rmse_40_train)\n",
    "rmse_40_train\n",
    "\n",
    "y_40_test_predicted = model_40.predict(X_40_test)\n",
    "\n",
    "rmse_40_test = np.sqrt(mean_squared_error(y_40_test, y_40_test_predicted))\n",
    "rmse_test.append(rmse_40_test)\n",
    "rmse_40_test\n",
    "\n",
    "X_41 = removing_outliers(X_41)\n",
    "\n",
    "X_41_train, X_41_test =  X_train_test_separation(X_41)\n",
    "y_41_train, y_41_test =  y_train_test_separation(X_41)\n",
    "\n",
    "X_41_train = pipeline_from_pickle.fit_transform(X_41_train)\n",
    "X_41_test = pipeline_from_pickle.transform(X_41_test)\n",
    "\n",
    "model_41 = lm.fit(X_41_train, y_41_train)\n",
    "\n",
    "y_41_train_predicted = model_41.predict(X_41_train)\n",
    "\n",
    "rmse_41_train = np.sqrt(mean_squared_error(y_41_train, y_41_train_predicted))\n",
    "rmse_train.append(rmse_41_train)\n",
    "rmse_41_train\n",
    "\n",
    "y_41_test_predicted = model_41.predict(X_41_test)\n",
    "\n",
    "rmse_41_test = np.sqrt(mean_squared_error(y_41_test, y_41_test_predicted))\n",
    "rmse_test.append(rmse_41_test)\n",
    "rmse_41_test\n",
    "\n",
    "X_57 = removing_outliers(X_57)\n",
    "\n",
    "X_57_train, X_57_test =  X_train_test_separation(X_57)\n",
    "y_57_train, y_57_test =  y_train_test_separation(X_57)\n",
    "\n",
    "X_57_train = pipeline_from_pickle.fit_transform(X_57_train)\n",
    "X_57_test = pipeline_from_pickle.transform(X_57_test)\n",
    "\n",
    "model_57 = lm.fit(X_57_train, y_57_train)\n",
    "\n",
    "y_57_train_predicted = model_57.predict(X_57_train)\n",
    "\n",
    "model_57.score(X_57_train, y_57_train)\n",
    "\n",
    "rmse_57_train = np.sqrt(mean_squared_error(y_57_train, y_57_train_predicted))\n",
    "rmse_train.append(rmse_57_train)\n",
    "rmse_57_train\n",
    "\n",
    "y_57_test_predicted = model_57.predict(X_57_test)\n",
    "\n",
    "rmse_57_test = np.sqrt(mean_squared_error(y_57_test, y_57_test_predicted))\n",
    "rmse_test.append(rmse_57_test)\n",
    "rmse_57_test\n",
    "\n",
    "print (\"Item\",\"\\t: \", \"rmse_train\",\"\\t \\t\", \"rmse_test\",\"\\t\\t\", \"r2\")\n",
    "for i in range(0,len(list_of_items)):\n",
    "    print (\" \",list_of_items[i],\"\\t: \", rmse_train[i],\"\\t\", rmse_test[i],\"\\t\", r2[i])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
